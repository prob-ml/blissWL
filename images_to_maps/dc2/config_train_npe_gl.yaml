---
defaults:
    - _self_
    - override hydra/job_logging: stdout

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

paths:
    dc2: /scratch/regier_root/regier1/twhit/data/dc2
    output: /scratch/regier_root/regier1/twhit/blissWL

variational_factors:
  - _target_: images_to_maps.variational_dist.IndependentMVNFactor
    name: shear_1
    dim: ${surveys.dc2.num_redshift_bins}
    nll_gating: null
  - _target_: images_to_maps.variational_dist.IndependentMVNFactor
    name: shear_2
    dim: ${surveys.dc2.num_redshift_bins}
    nll_gating: null
  - _target_: images_to_maps.variational_dist.IndependentMVNFactor
    name: convergence
    dim: ${surveys.dc2.num_redshift_bins}
    nll_gating: null

lensing_normalizers_nan:
    nan:
        _target_: images_to_maps.image_normalizer.NanNormalizer

lensing_normalizers_nanpsf:
    nan:
        _target_: images_to_maps.image_normalizer.NanNormalizer
    psf:
        _target_: images_to_maps.image_normalizer.PsfAsImage
        num_psf_params: 4

lensing_metrics:
    _target_: images_to_maps.metrics.WeakLensingMetrics
    num_redshift_bins: ${surveys.dc2.num_redshift_bins}

lensing_plots:
    _target_: images_to_maps.plots.WeakLensingPlots
    frequency: 1
    save_local: ${paths.output}/${train.trainer.logger.name}/${train.trainer.logger.version}/lensing_plots

encoder:
    _target_: images_to_maps.encoder.MassMapEncoder
    n_bands: 6
    res_init: 2048  # num pixels per side
    res_midpoint: 128
    res_final: 8  # num tiles per side
    ch_init: 64
    ch_max: 1024
    ch_final: 128
    initial_downsample: false
    more_up_layers: true
    num_bottleneck_layers: 0
    image_normalizers: ${lensing_normalizers_nanpsf}
    var_dist:
        _target_: images_to_maps.variational_dist.VariationalDist
        tile_slen: ${surveys.dc2.tile_slen}
        factors: ${variational_factors}
    optimizer_params:
        lr: 1e-4
    scheduler_params:
        milestones: []
        gamma: 1.0
    loss_plots_location: ${paths.output}/${train.trainer.logger.name}/${train.trainer.logger.version}/loss_plots
    mode_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${lensing_metrics}
    sample_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${lensing_metrics}
    sample_image_renders:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${lensing_plots}

surveys:
    dc2:
        _target_: images_to_maps.dc2.dc2.LensingDC2DataModule
        dc2_image_dir: /data/scratch/dc2_nfs/run2.2i-dr6-v4/coadd-t3828-t3829/deepCoadd-results/
        dc2_cat_path: ${paths.dc2}/dc2_lensing_catalog.pkl
        image_slen: 4096
        n_image_split: 2  # split into n_image_split**2 subimages
        tile_slen: 256
        splits: 0:80/80:90/90:100
        avg_ellip_kernel_size: 15  # must be odd
        avg_ellip_kernel_sigma: 15
        redshift_quantiles: [0.00, 0.762988, 1.120420, 1.592735]
        num_redshift_bins: 4  # length of redshift_quantiles
        batch_size: 1
        num_workers: 1
        cached_data_path: ${paths.dc2}/dc2_lensing_splits
        train_transforms:
            - _target_: images_to_maps.data_augmentation.LensingRotateFlipTransform
        shuffle_file_order: false  # partition train/val/test by ra/dec so that we can compute 2PCFs on spatially contiguous test set

mode: train

train:
    trainer:
        _target_: lightning.Trainer
        logger:
            _target_: lightning.pytorch.loggers.TensorBoardLogger
            save_dir: ${paths.output}
            name: results/dc2/npe
            version: nanpsf_${encoder.ch_max}_${encoder.initial_downsample}_${encoder.more_up_layers}
            default_hp_metric: false
        reload_dataloaders_every_n_epochs: 0
        check_val_every_n_epoch: 1
        log_every_n_steps: 10
        max_epochs: 300
        accelerator: gpu
        devices: 1
        precision: 32-true
    callbacks:
        checkpointing:
            _target_: lightning.pytorch.callbacks.ModelCheckpoint
            filename: "encoder_{epoch}"
            save_top_k: 1
            verbose: true
            monitor: val/_loss
            mode: min
            save_on_train_epoch_end: false
        early_stopping:
            _target_: lightning.pytorch.callbacks.EarlyStopping
            monitor: val/_loss
            mode: min
            patience: 100
    data_source: ${surveys.dc2}
    encoder: ${encoder}
    seed: 123123
    pretrained_weights: null
    ckpt_path: null
    matmul_precision: high
